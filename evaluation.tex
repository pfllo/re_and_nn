\section{Evaluation Methodology}
Our experiments
\cyan{aim to} %are designed
to answer three questions: \textbf{Q1:} Does the use of \REs enhance the learning quality when the number of annotated
instances is small?  \textbf{Q2:}  Does the use of \REs still helps when using the full training data?
 \textbf{Q3:}  How can we choose from different combination methods?
%When do the three proposed methods work, and which method works best in each scenario?
% \todo{how to refer to question (3) in exp?}

\subsection{Datasets}
\label{sec_datasest}

We use the ATIS dataset~\cite{hemphill1990atis} to evaluate our approach, which is widely used in \SLU research, and
includes queries of flights, meal, etc. We follow the setup of Liu and Lane~\shortcite{liu2016attention} by using 4,978 queries for training and 893 for
testing, with 18 intent labels and 127 slot labels.
% Numbers are replaced with special tokens like \textsl{\underline{DIGIT*m}},
% where \emph{m} is the number of digits in the original string.
%Different from previous work, 
We also split words like
\textsl{\underline{Miami's}} into \textsl{\underline{Miami 's}} to reduce the number of words that do not have a pre-trained word
embedding, which is helpful for few-shot learning.

To answer  \textbf{Q1} , we also exploit the \textbf{\emph{full few-shot learning setting}}. Specifically, for intent detection, we randomly
select 5, 10, 20 training instances for each intent to form the few-shot training set; and for slot filling, we also explore 5, 10, 20
shots settings. However, since a sentence typically contains multiple slots, the number of frequent slot labels may inevitably exceed
the target shot count. To better approximate the target shot count, \red{we select sentences for each slot label  in the
ascending order of the label frequency.}
% As for slot filling, we first sort the slot labels by frequence, and randomly select sentences for the least-frequent slot label first, then the more frequent labels afterwards one by one. Although we also explore 5, 10, 20 shots settings, since one sentence typically involves multiple slots, the number of frequent slot labels may inevitably exceed the target number of shots.
$k_1$-shot dataset contains $k_2$-shot dataset if $k_1>k_2$.
All settings use the original test set.
% After that, we move to the adjacent label which is slightly more frequent, and make sure the number of training instances meet the threshold.

Since most few-shot learning methods require either extra classes or classes with enough data for training, we also explore the
\textbf{\emph{partial few-shot learning setting}} for intent detection to make fair comparison with existing few-shot learning methods.
Specifically, we let the 3 most frequent intents have 300 training instances, and the rest remains untouched.
This is also a common scenario in real world, where we often have several frequent classes and many classes with limited data.

\subsection{Preparing REs}
\label{re_in_exp} We use the standard \RE grammar in this work. Our \REs are written by an \cyan{paid} annotator 
who is familiar \red{with the dataset.}
% \footnote{Code and data are available at: [url redacted for double-blind review].}.
It took the annotator in total less than 10 hours
to develop all the \REs, while a domain expert can accomplish the task faster. We use the 20-shot data to develop the \REs, but word lists
like cities are obtained from the full training set. The majority of the time 
for %spent on 
writing the \REs is proportional to the number of \RE groups. 
It took about 1.5 hours to write the 54 intent \REs with on average 2.2 groups per \RE. It is straightforward
to write the slot \REs for \cyan{the input and output side methods}, for which it took around
 1 hour to write the 60 \REs with averagely 1.7 groups. By contrast, writing slot \REs to guide attention requires more
efforts as the annotator needs to carefully select clue words and \cyan{annotate} the full slot label. As a result, it took about 
5.5 hours to generate 115 \REs with on average 3.3 groups.
% The performance of the sets of \REs used for the method described in
% Sec.~\ref{interact_with_module} is given in Table~\ref{tab_full_few}.

%Writing an intent \RE takes about 1-2 minutes. In this work, the student spent 1.5 hours to write the 54 \REs, with on average 2.2 \RE
%groups for each \RE. The student finds that writing the slot \RE for the methods described in Sec.~\ref{fusion_with_input} and
%\ref{fusion_with_output} to be easy, since we only annotate a simplified version of the slot label. On average, it takes less than two
%minutes to write a \RE. It took the student about an hour to write the 60 \REs with on average 1.7 \RE group. In contrast to the two
%aforementioned tasks, writing slot \REs to guide attention requires more efforts. This is because we need to carefully select clue words
%and target for the full slot label. As a result, it took between 2 to 5 minutes to write one \RE, yielding in total 5.5 hours for writing
%115 \REs with on average 3.3 \RE groups. The performance of the intent \REs and the slot \REs for the method described in
%Sec.~\ref{interact_with_module} is shown in Table~\ref{tab_full_few}.

%We use the standard \RE grammar in this work. Our \REs are written by an undergraduate who is familiar with the dataset\footnote{Code and
%data are available at: [url redacted for double-blind review].}.  It took the student in total less than 10 hours to develop all the \REs,
%but a domain expert can accomplish the task faster. We use the 20-shot data to develop the \REs, but word lists like cities are obtained
%from the full training set. The majority of the time spent on writing the \REs is proportional to the number of \RE groups. Writing an
%intent \RE takes about 1-2 minutes. In this work, the student spent 1.5 hours to write the 54 \REs, with on average 2.2 \RE groups for each
%\RE. The student finds that writing the slot \RE for the methods described in Sec.~\ref{fusion_with_input} and \ref{fusion_with_output} to
%be easy, since we only annotate a simplified version of the slot label. On average, it takes less than two minutes to write a \RE. It took
%the student about an hour to write the 60 \REs with on average 1.7 \RE group. In contrast to the two aforementioned tasks, writing slot
%\REs to guide attention requires more efforts. This is because we need to carefully select clue words and target for the full slot label.
%As a result, it took between 2 to 5 minutes to write one \RE, yielding in total 5.5 hours for writing 115 \REs with on average 3.3 \RE
%groups. The performance of the intent \REs and the slot \REs for the method described in Sec.~\ref{interact_with_module} is shown in
%Table~\ref{tab_full_few}.


% 54 patterns are collected in total
%\orange{(used 1.5 hours)}, with averagely 2.2 (from 1 to 4) \RE groups for each \RE (the group matching a sequence of any words is not
%included). Similarly, writing slot patterns for methods in Sec.~\ref{fusion_with_input} and \ref{fusion_with_output} is also easy since we
%only annotate a simplified version of the slot label. It takes 1-2 minutes to write an \RE, and 60 patterns are produced \orange{(used 70
%minutes)}, with averagely 1.7 (from 1 to 3) \RE groups. However, writing slot patterns to guide attention is more difficult, since we need
%to carefully select informative words and target to the full slot label as well. Typically, writing one pattern requires 2-5 minutes, and
%115 patterns \orange{(used 5.5 hours)} with averagely 3.3 (from 2 to 8) \RE groups are produced. The performance of the intent \texttt{RE}s
%and the slot \texttt{RE}s for the method in Sec.~\ref{interact_with_module} is shown in Table~\ref{tab_full_few}. \FIXME{ZW: We need to
%state in total how long did it take to derive all the REs. State which \RE convention is used. } \orange{LUO to ZW: see the newly added
%orange parts}


\subsection{Experimental Setup}
\cparagraph{Hyper-parameters}
Our hyper-parameters for \BLSTM are similar to the ones in Liu and Lane~\shortcite{liu2016attention},
% We use similar hyper-parameters to Liu and Lane~\shortcite{liu2016attention} for \BLSTM,
% which gives comparable results on the original dataset.
% Specifically, we set the batch size to 16, the dropout probability to 0.5, the \BLSTM size to 200 (100 for each direction),
Specifically, we use batch size 16, dropout probability 0.5, \BLSTM cell size 100.
The attention loss weight is 16 (both positive and negative) for full few-shot and 1 for other settings.
We use the 100d GloVe word vectors~\cite{pennington2014glove}, and the Adam optimizer~\cite{kingma2014adam} with learning rate 0.001.

\cparagraph{Evaluation Metrics}
We report accuracy and macro-F1 for intent detection, and micro/macro-F1 for slot filling.
Micro/macro-F1 are the harmonic mean of micro/macro precision and recall.
Macro-precision/recall are calculated by averaging precision/recall of each label, and micro-precision/recall are averaged over each prediction.
% While accuracy and micro statistics show performance on all the instances, macro statitics are more sensitive to classes with limited data.

\cparagraph{Naming Conventions}
% We use the following naming conventions when discussing our experimental results:
%
\texttt{BLSTM} is our base model,
\texttt{+feat} means using \REtag as input features (Sec.~\ref{fusion_with_input}),
% input side method in
\ptatt is the two-side attention method without attention loss,
\texttt{+posi} and \texttt{+neg} refer to using positive and negative attention loss, respectively, \texttt{+both} refers to using both attention losses (Sec.~\ref{interact_with_module}),
% \NN module side method in
\texttt{+logit} means using \REtag to modify \NN output (Sec.~\ref{fusion_with_output}),
% output side methods in
\texttt{RE} refers to using \RE output as prediction directly\footnote{
For slot filling, \REs for Sec.~\ref{interact_with_module} are used.},
\texttt{+hu16} is the method of Hu et al.~\shortcite{hu2016harnessing},
\texttt{+mem} is the memory module of Kaiser et al.~\shortcite{kaiser2017learning}\footnote{
We tune $C$ and $\pi_0$ of \texttt{hu16}, and choose (0.1, 0.3) for intent, and (1, 0.3) for slot. We tune memory-size and $k$ of \texttt{mem}, and choose (1024, 64) for intent, and (2048, 64) for slot.
},
\LL is the state-of-art joint model~\cite{liu2016attention} in ATIS.